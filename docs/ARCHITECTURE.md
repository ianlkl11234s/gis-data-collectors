# Data Collectors 架構文件

本文件說明 Data Collectors 的系統架構與資料歸檔流程。

## 系統概覽

```
┌─────────────────────────────────────────────────────────────────┐
│                     Data Collectors Service                       │
│                        (Zeabur 部署)                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                   │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  YouBike    │  │   Weather   │  │     VD      │  ...         │
│  │  Collector  │  │  Collector  │  │  Collector  │              │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘              │
│         │                │                │                      │
│         └────────────────┼────────────────┘                      │
│                          │                                       │
│                          ▼                                       │
│              ┌───────────────────────┐                           │
│              │    Local Storage      │  ← 最近 7 天資料          │
│              │    (/data volume)     │                           │
│              └───────────┬───────────┘                           │
│                          │                                       │
│                          │ 每日 03:00                            │
│                          ▼                                       │
│              ┌───────────────────────┐                           │
│              │    Archive Task       │                           │
│              │    (同步 & 清理)      │                           │
│              └───────────┬───────────┘                           │
│                          │                                       │
└──────────────────────────┼───────────────────────────────────────┘
                           │
                           ▼
              ┌───────────────────────┐
              │      AWS S3           │  ← 永久歸檔
              │ (ap-southeast-2)      │
              │ migu-gis-data-collector│
              └───────────────────────┘
```

## 儲存架構

### 雙層儲存策略

| 層級 | 儲存位置 | 資料範圍 | 用途 | 成本 |
|------|----------|----------|------|------|
| 熱資料 | Zeabur Volume | 最近 7 天 | 快速存取 | ~$0.15/GB/月 |
| 冷資料 | AWS S3 Standard | 全部歷史 | 永久歸檔 | ~$0.023/GB/月 |

### 成本估算 (50GB 資料/月)

- **純 Zeabur**: $7.50/月
- **Zeabur + S3**: $0.75 (Zeabur 5GB) + $1.04 (S3 45GB) = **$1.79/月**
- **節省**: 約 76%

## 資料流程

### 1. 收集階段

```
TDX API ────┐
CWA API ────┼──► Collectors ──► Local Storage (/data)
其他 API ───┘
```

每個收集器定期從外部 API 取得資料：
- YouBike: 每 15 分鐘
- Weather: 每 60 分鐘
- VD: 每 5 分鐘
- Temperature: 每 60 分鐘
- Parking: 每 15 分鐘

### 2. 儲存格式

```
/data/
├── youbike/
│   ├── latest.json           # 最新資料快取
│   └── 2025/
│       └── 12/
│           └── 26/
│               ├── youbike_0900.json
│               ├── youbike_0915.json
│               └── ...
├── weather/
│   └── ...
├── vd/
│   └── ...
├── temperature/
│   └── ...
└── parking/
    └── ...
```

### 3. 歸檔階段

每日 03:00 執行歸檔任務：

```
┌─────────────────────────────────────────┐
│           Archive Task                   │
├─────────────────────────────────────────┤
│ 1. 遍歷本地資料目錄                      │
│ 2. 上傳到 S3 (跳過已存在)                │
│ 3. 刪除 > 7 天的本地檔案                 │
│ 4. 清理空目錄                            │
└─────────────────────────────────────────┘
```

### 4. 讀取階段

API 自動選擇資料來源：

```
API Request
    │
    ▼
┌─────────────────┐
│ 檢查本地檔案    │
└────────┬────────┘
         │
    存在？│
         │
    ┌────┴────┐
    │         │
   是        否
    │         │
    ▼         ▼
┌───────┐  ┌──────────┐
│ 本地  │  │ 從 S3    │
│ 讀取  │  │ 讀取     │
└───────┘  └──────────┘
```

## S3 儲存結構

```
migu-gis-data-collector/
├── youbike/
│   ├── latest.json
│   └── 2025/
│       └── 12/
│           ├── 20/
│           │   ├── youbike_0900.json
│           │   └── ...
│           ├── 21/
│           ├── 22/
│           └── ...
├── weather/
│   └── ...
├── vd/
│   └── ...
├── temperature/
│   └── ...
└── parking/
    └── ...
```

## 環境變數設定

### 必要設定

```bash
# S3 設定
S3_BUCKET=migu-gis-data-collector
S3_ACCESS_KEY=your_access_key
S3_SECRET_KEY=your_secret_key
S3_REGION=ap-southeast-2

# API 設定
API_KEY=your_api_key
```

### 可選設定

```bash
# 歸檔設定
ARCHIVE_ENABLED=true          # 是否啟用歸檔 (預設 true)
ARCHIVE_RETENTION_DAYS=7      # 本地保留天數 (預設 7)
ARCHIVE_TIME=03:00            # 每日歸檔時間 (預設 03:00)
```

## 故障處理

### S3 連線失敗

- 歸檔任務會跳過，不影響收集器運作
- 本地資料繼續累積
- 下次執行時會重試

### 資料不一致

- 上傳 S3 成功後才刪除本地
- 刪除前會確認 S3 已有檔案
- 防止資料遺失

### 空間不足

- 如果本地空間不足，歸檔任務會清理過期資料
- 建議監控 Zeabur Volume 使用量
- 可調整 `ARCHIVE_RETENTION_DAYS` 減少本地保留

## 監控與維護

### 歸檔狀態 API

```bash
curl -H "X-API-Key: your_key" \
  https://your-app.zeabur.app/api/archive/status
```

回應包含：
- 歸檔是否啟用
- S3 連線狀態
- 各收集器的本地/S3 檔案數量與大小

### 日誌輸出

歸檔任務執行時會輸出：
```
============================================================
📦 開始歸檔任務
============================================================
   時間: 2025-12-26 03:00:00
   保留天數: 7
   S3 Bucket: migu-gis-data-collector

📤 同步資料到 S3...
   ✓ parking: 上傳 96 個檔案
   - youbike: 已同步 (96 個檔案)

🗑️  清理過期資料 (>7 天)...
   ✓ parking: 刪除 96 個過期檔案

============================================================
📊 歸檔完成
============================================================
   同步: 上傳 96 | 跳過 480 | 失敗 0
   清理: 刪除 96 個檔案 | 保留 480 個檔案
============================================================
```

## 安全考量

### IAM 權限

S3 存取只需要以下權限：
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:ListBucket",
        "s3:HeadObject"
      ],
      "Resource": [
        "arn:aws:s3:::migu-gis-data-collector",
        "arn:aws:s3:::migu-gis-data-collector/*"
      ]
    }
  ]
}
```

### 最佳實踐

1. 使用專用 IAM 使用者，不要使用 root 帳號
2. 定期輪換 Access Key
3. 啟用 S3 版本控制防止誤刪
4. 考慮設定 S3 生命週期規則進一步降低成本

## 擴展考量

### 增加收集器

1. 建立新的收集器類別繼承 `BaseCollector`
2. 在 `config.py` 加入相關設定
3. 在 `main.py` 初始化收集器
4. 歸檔任務會自動處理新的收集器目錄

### 多區域部署

如需多區域部署，可考慮：
- S3 跨區域複寫
- 各區域獨立的 Zeabur 服務
- 統一的 S3 歸檔儲存

### 資料生命週期

可設定 S3 生命週期規則：
- 30 天後轉移到 S3 Infrequent Access（成本降低 40%）
- 90 天後轉移到 S3 Glacier（成本降低 80%）
- 根據需求設定過期刪除
